{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, pandas as pd, bs4, re, nltk, sklearn, numpy as np, xgboost\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_test_11.1.16_v4.csv',\n",
       " 'archive',\n",
       " 'R_training_subset_11.1.16.csv',\n",
       " 'provider type files',\n",
       " 'model_test_11.1.16_v3.csv',\n",
       " 'training_subset_11.1.16.xlsx',\n",
       " 'clean_model_text.csv',\n",
       " 'BoW-RF_test1_paradata_11.1.16.xlsx',\n",
       " 'train_v.csv',\n",
       " 'test_v.csv',\n",
       " 'test_results_T1.csv',\n",
       " 'R_model_test_11.1.16_v2.csv',\n",
       " 'model_test_11.1.16_v3.xlsx',\n",
       " 'model_test_11.1.16_v4.xlsx',\n",
       " 'model_test_11.1.16.xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the working directory to the folder where your data is stored\n",
    "os.chdir(\"P:\\\\7670\\Common\\\\2. Ad hoc requests (Task 2F )\\Star Ratings\\Cross-site\\Marketing scan\\August 2016\\\\99_Idea Lab\\Work\\Week 11\\Training Datasets\")\n",
    "# See what files are in the folder.\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>p_type</th>\n",
       "      <th>root</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>coded_page_mm</th>\n",
       "      <th>coded_site_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HC</td>\n",
       "      <td>okheart.com</td>\n",
       "      <td>https://www.okheart.com/physicians/jerome-p-ma...</td>\n",
       "      <td>skip main content menu pay bill give careers l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>abbevilleareamc.com</td>\n",
       "      <td>http://www.abbevilleareamc.com/volunteers/appl...</td>\n",
       "      <td>abbeville area medical center slider volunteer...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HC</td>\n",
       "      <td>cch-inc.com</td>\n",
       "      <td>https://www.cch-inc.com/health-wellness/educat...</td>\n",
       "      <td>body navigation logo columbus community hospit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HHC</td>\n",
       "      <td>homecareofcommonwealth.com</td>\n",
       "      <td>http://www.homecareofcommonwealth.com/northeas...</td>\n",
       "      <td>careers contact us espanol call us today us ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>HC</td>\n",
       "      <td>bellevuehospital.com</td>\n",
       "      <td>http://www.bellevuehospital.com/Hospital%20Ser...</td>\n",
       "      <td>1400 west main street bellevue ohio 44811 us p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id p_type                        root  \\\n",
       "0   1     HC                 okheart.com   \n",
       "1   2     HC         abbevilleareamc.com   \n",
       "2   3     HC                 cch-inc.com   \n",
       "3   4    HHC  homecareofcommonwealth.com   \n",
       "4   5     HC        bellevuehospital.com   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.okheart.com/physicians/jerome-p-ma...   \n",
       "1  http://www.abbevilleareamc.com/volunteers/appl...   \n",
       "2  https://www.cch-inc.com/health-wellness/educat...   \n",
       "3  http://www.homecareofcommonwealth.com/northeas...   \n",
       "4  http://www.bellevuehospital.com/Hospital%20Ser...   \n",
       "\n",
       "                                                text  coded_page_mm  \\\n",
       "0  skip main content menu pay bill give careers l...              0   \n",
       "1  abbeville area medical center slider volunteer...              0   \n",
       "2  body navigation logo columbus community hospit...              0   \n",
       "3  careers contact us espanol call us today us ho...              0   \n",
       "4  1400 west main street bellevue ohio 44811 us p...              0   \n",
       "\n",
       "   coded_site_mm  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data\n",
    "train = pd.read_excel(\"model_test_11.1.16_v4.xlsx\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "#   \"header=0\" indicates that the first line of the file contains column names, \n",
    "#   \"delimiter=\\t\" indicates that the fields are separated by tabs,\n",
    "#   quoting=3 tells Python to ignore doubled quotes, otherwise you may encounter errors trying to read the file.\n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MM_to_words( raw_MM ):\n",
    "    # Function to convert a raw CMS MM to a string of words\n",
    "    # The input is a single string (a raw MM text), and \n",
    "    # the output is a single string (a preprocessed MM text)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    MM_text = BeautifulSoup(raw_MM,\"lxml\").get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", MM_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #    a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    #    to make the output easier to use in our Bag of Words,\n",
    "    #    then return the result. \n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set CMS MMs...\n",
      "\n",
      "MM 1000 of 27239\n",
      "\n",
      "MM 2000 of 27239\n",
      "\n",
      "MM 3000 of 27239\n",
      "\n",
      "MM 4000 of 27239\n",
      "\n",
      "MM 5000 of 27239\n",
      "\n",
      "MM 6000 of 27239\n",
      "\n",
      "MM 7000 of 27239\n",
      "\n",
      "MM 8000 of 27239\n",
      "\n",
      "MM 9000 of 27239\n",
      "\n",
      "MM 10000 of 27239\n",
      "\n",
      "MM 11000 of 27239\n",
      "\n",
      "MM 12000 of 27239\n",
      "\n",
      "MM 13000 of 27239\n",
      "\n",
      "MM 14000 of 27239\n",
      "\n",
      "MM 15000 of 27239\n",
      "\n",
      "MM 16000 of 27239\n",
      "\n",
      "MM 17000 of 27239\n",
      "\n",
      "MM 18000 of 27239\n",
      "\n",
      "MM 19000 of 27239\n",
      "\n",
      "MM 20000 of 27239\n",
      "\n",
      "MM 21000 of 27239\n",
      "\n",
      "MM 22000 of 27239\n",
      "\n",
      "MM 23000 of 27239\n",
      "\n",
      "MM 24000 of 27239\n",
      "\n",
      "MM 25000 of 27239\n",
      "\n",
      "MM 26000 of 27239\n",
      "\n",
      "MM 27000 of 27239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's loop through and clean all of the training set at once\n",
    "\n",
    "# Get the number of MMs based on the dataframe column size\n",
    "num_MM = train[\"text\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean MMs\n",
    "clean_train_MM = []\n",
    "\n",
    "# Loop over each MM; create an index i that goes from 0 to the length\n",
    "# of theMM list \n",
    "for i in range( 0, num_MM ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean MMs\n",
    "    clean_train_MM.append( MM_to_words( train[\"text\"][i] ) )\n",
    "\n",
    "# This next bit is optional, and it will give you status updates for every 1,000 rows.\n",
    "print (\"Cleaning and parsing the training set CMS MMs...\\n\")\n",
    "clean_train_MM = []\n",
    "for i in range( 0, num_MM ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print (\"MM %d of %d\\n\" % ( i+1, num_MM ))                                                                    \n",
    "    clean_train_MM.append( MM_to_words( train[\"text\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "\n",
    "import sklearn\n",
    "# If you are using Anaconda, Sci-Kit Learn should already be installed. Otherwise you will have to install it.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,\n",
    "                             ngram_range=(1, 3),\n",
    "                             max_features = 10000) # This limits to the 10,000 most frequent words\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_MM)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \\\n",
    "\n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "\n",
    "# NOTE: CountVectorizer comes with its own options to automatically do preprocessing,\n",
    "# tokenization, and stop word removal -- for each of these, instead of specifying \"None\",\n",
    "# we could have used a built-in method or specified our own function to use.\n",
    "# However, we wanted to write our own function for data cleaning in this tutorial \n",
    "# to show you how it's done step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "model=XGBClassifier()\n",
    "trainpredictors=train_data_features.toarray()\n",
    "outcome=np.array(train['page_MM'])\n",
    "model.fit(trainpredictors, outcome)\n",
    "expected=outcome\n",
    "predicted_train=model.predict(trainpredictors)\n",
    "print(metrics.classification_report(expected, predicted_train))\n",
    "print(metrics.confusion_matrix(expectedtrain, predicted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that when we use the Bag of Words for the test set we only call \"transform\", \n",
    "#  not \"fit_transform\" as we did for the training set. \n",
    "# In machine learning, you shouldn't use the test set to fit your model, \n",
    "# otherwise you run the risk of overfitting. \n",
    "# For this reason, we keep the test set off-limits until we are ready to make predictions.\n",
    "\n",
    "# Read the test data\n",
    "test = pd.read_excel(\"model_test_11.1.16.xlsx\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the test set MMs...\n",
      "\n",
      "CMS MM 1000 of 27322\n",
      "\n",
      "CMS MM 2000 of 27322\n",
      "\n",
      "CMS MM 3000 of 27322\n",
      "\n",
      "CMS MM 4000 of 27322\n",
      "\n",
      "CMS MM 5000 of 27322\n",
      "\n",
      "CMS MM 6000 of 27322\n",
      "\n",
      "CMS MM 7000 of 27322\n",
      "\n",
      "CMS MM 8000 of 27322\n",
      "\n",
      "CMS MM 9000 of 27322\n",
      "\n",
      "CMS MM 10000 of 27322\n",
      "\n",
      "CMS MM 11000 of 27322\n",
      "\n",
      "CMS MM 12000 of 27322\n",
      "\n",
      "CMS MM 13000 of 27322\n",
      "\n",
      "CMS MM 14000 of 27322\n",
      "\n",
      "CMS MM 15000 of 27322\n",
      "\n",
      "CMS MM 16000 of 27322\n",
      "\n",
      "CMS MM 17000 of 27322\n",
      "\n",
      "CMS MM 18000 of 27322\n",
      "\n",
      "CMS MM 19000 of 27322\n",
      "\n",
      "CMS MM 20000 of 27322\n",
      "\n",
      "CMS MM 21000 of 27322\n",
      "\n",
      "CMS MM 22000 of 27322\n",
      "\n",
      "CMS MM 23000 of 27322\n",
      "\n",
      "CMS MM 24000 of 27322\n",
      "\n",
      "CMS MM 25000 of 27322\n",
      "\n",
      "CMS MM 26000 of 27322\n",
      "\n",
      "CMS MM 27000 of 27322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list and append the clean MMs one by one\n",
    "num_MM = len(test[\"text\"])\n",
    "clean_test_MM = [] \n",
    "\n",
    "print (\"Cleaning and parsing the test set MMs...\\n\")\n",
    "for i in range(0,num_MM):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print (\"CMS MM %d of %d\\n\" % (i+1, num_MM))\n",
    "    clean_MM = MM_to_words( test[\"text\"][i] )\n",
    "    clean_test_MM.append( clean_MM )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testpredictors=test_data_features.toarray()\n",
    "outcome=np.array(test['page_MM'])\n",
    "model.fit(testpredictors, outcome)\n",
    "expected=outcome\n",
    "predicted_test=model.predict(testpredictors)\n",
    "print(metrics.classification_report(expected, predicted_test))\n",
    "print(metrics.confusion_matrix(expected, predicted_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
